{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second & Third Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing\n",
    "In this part, the main goal is to seperate training and testing data, filter out useless information, and combine tweets with emotions as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_identification.csv\n",
    "train_test_set = pd.read_csv(\"data_identification.csv\",\n",
    "                         header=None, names=[\"id\", \"identification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet_id</td>\n",
       "      <td>identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  identification\n",
       "0  tweet_id  identification\n",
       "1  0x28cc61            test\n",
       "2  0x29e452           train\n",
       "3  0x2b3819           train\n",
       "4  0x2db41f            test"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the first title row\n",
    "train_test_set = train_test_set.drop([0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id identification\n",
       "1  0x28cc61           test\n",
       "2  0x29e452          train\n",
       "3  0x2b3819          train\n",
       "4  0x2db41f           test\n",
       "5  0x2a2acc          train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train_test_set[train_test_set['identification']=='train'].filter(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = train_test_set[train_test_set['identification']=='test'].filter(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x29e452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2b3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x2a2acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x2a8830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x20b21d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x2452cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x2d729d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0x2ab56d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0x1f3657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0x1fcc53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id\n",
       "2   0x29e452\n",
       "3   0x2b3819\n",
       "5   0x2a2acc\n",
       "6   0x2a8830\n",
       "7   0x20b21d\n",
       "8   0x2452cf\n",
       "9   0x2d729d\n",
       "10  0x2ab56d\n",
       "11  0x1f3657\n",
       "12  0x1fcc53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455563"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411972"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emotion.csv\n",
    "emotion_set = pd.read_csv(\"emotion.csv\",\n",
    "                         header=None, names=[\"id\", \"emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the first title row\n",
    "emotion_set = emotion_set.drop([0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x3140b1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x368b73</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x296183</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2bd6e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x2ee1dd</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x34cd80</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x33f099</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x2ae7b7</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x2408d4</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0x2b193b</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       emotion\n",
       "1   0x3140b1       sadness\n",
       "2   0x368b73       disgust\n",
       "3   0x296183  anticipation\n",
       "4   0x2bd6e1           joy\n",
       "5   0x2ee1dd  anticipation\n",
       "6   0x34cd80           joy\n",
       "7   0x33f099       sadness\n",
       "8   0x2ae7b7       sadness\n",
       "9   0x2408d4         trust\n",
       "10  0x2b193b       sadness"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_set[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455563"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emotion_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save to pickle file\n",
    "emotion_set.to_pickle(\"train_df.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_DM.json\n",
    "tweets_df = pd.read_json(\"tweets_DM.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score          _index                                            _source  \\\n",
       "0     391  hashtag_tweets  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
       "1     433  hashtag_tweets  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
       "2     232  hashtag_tweets  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
       "3     376  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
       "4     989  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
       "\n",
       "            _crawldate   _type  \n",
       "0  2015-05-23 11:42:47  tweets  \n",
       "1  2016-01-28 04:52:09  tweets  \n",
       "2  2017-12-25 04:39:20  tweets  \n",
       "3  2016-01-24 23:53:05  tweets  \n",
       "4  2016-01-08 17:18:59  tweets  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_source_df = tweets_df['_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['text'] = tweets_source_df.apply(lambda x: x['tweet']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['id'] = tweets_df['_source'].apply(lambda x: x['tweet']['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_tweets_df = tweets_df.filter(['text','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>0x376b20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>0x2d5350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>0x28b412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>0x2de201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        id\n",
       "0  People who post \"add me on #Snapchat\" must be ...  0x376b20\n",
       "1  @brianklaas As we see, Trump is dangerous to #...  0x2d5350\n",
       "2  Confident of your obedience, I write to you, k...  0x28b412\n",
       "3                Now ISSA is stalking Tasha 😂😂😂 <LH>  0x1cd5b0\n",
       "4  \"Trust is not the same as faith. A friend is s...  0x2de201"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets_df = filter_tweets_df[filter_tweets_df['id'].isin(train_ids['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets_df = filter_tweets_df[~filter_tweets_df['id'].isin(train_ids['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455563"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411972"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>0x376b20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>0x2d5350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>0x1d755c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>0x2c91a8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        id\n",
       "0  People who post \"add me on #Snapchat\" must be ...  0x376b20\n",
       "1  @brianklaas As we see, Trump is dangerous to #...  0x2d5350\n",
       "3                Now ISSA is stalking Tasha 😂😂😂 <LH>  0x1cd5b0\n",
       "5  @RISKshow @TheKevinAllison Thx for the BEST TI...  0x1d755c\n",
       "6       Still waiting on those supplies Liscus. <LH>  0x2c91a8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>0x28b412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>0x2de201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>0x218443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>0x2939d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>0x26289a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text        id\n",
       "2   Confident of your obedience, I write to you, k...  0x28b412\n",
       "4   \"Trust is not the same as faith. A friend is s...  0x2de201\n",
       "9   When do you have enough ? When are you satisfi...  0x218443\n",
       "30  God woke you up, now chase the day #GodsPlan #...  0x2939d5\n",
       "33  In these tough times, who do YOU turn to as yo...  0x26289a"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add emotion labels to train dataframe\n",
    "train_tweets_df = train_tweets_df.merge(emotion_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save to pickle file\n",
    "train_tweets_df.to_pickle(\"train_tweets_df.pkl\") \n",
    "test_tweets_df.to_pickle(\"test_tweets_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network and training processing below is following deep learning example in lab2, but I adjust the number of feature, training data and epoch in order to get better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For 300 features:\n",
    "#### (1) Transform sentences into 300 features bag-of-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"train_tweets_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle(\"test_tweets_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "BOW_vectorizer = CountVectorizer(max_features=300, tokenizer=nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "num_of_train = 500000\n",
    "# 1. Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "BOW_vectorizer.fit(train_df['text'][:num_of_train])\n",
    "\n",
    "# 2. Transform documents to document-term matrix.\n",
    "X_train = BOW_vectorizer.transform(train_df['text'][:num_of_train])\n",
    "y_train = train_df['emotion'][:num_of_train]\n",
    "X_test = BOW_vectorizer.transform(train_df['text'][1400000:])\n",
    "y_test = train_df['emotion'][1400000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Build neural network\n",
    "I translate labels into one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (500000, 300)\n",
      "y_train.shape:  (500000,)\n",
      "X_test.shape:  (55563, 300)\n",
      "y_test.shape:  (55563,)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "## check dimension is a good habbit \n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:7]:\n",
      " 0    anticipation\n",
      "1         sadness\n",
      "2            fear\n",
      "3             joy\n",
      "4    anticipation\n",
      "5             joy\n",
      "6         sadness\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (500000,)\n",
      "y_test.shape:  (55563,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:7]:\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (500000, 8)\n",
      "y_test.shape:  (55563, 8)\n"
     ]
    }
   ],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:7]:\\n', y_train[0:7])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:7]:\\n', y_train[0:7])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  300\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network includes 2 ReLU hidden layers, and a softmax function to transform output from output layer. Besides, the loss function and optimizer is cross entropy and adam, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                19264     \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 23,944\n",
      "Trainable params: 23,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=64)(X)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=64)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "15625/15625 [==============================] - 22s 1ms/step - loss: 1.4924 - accuracy: 0.4556 - val_loss: 1.4610 - val_accuracy: 0.4629\n",
      "Epoch 2/25\n",
      "15625/15625 [==============================] - 21s 1ms/step - loss: 1.4431 - accuracy: 0.4727 - val_loss: 1.4507 - val_accuracy: 0.4683\n",
      "Epoch 3/25\n",
      "15625/15625 [==============================] - 23s 1ms/step - loss: 1.4293 - accuracy: 0.4772 - val_loss: 1.4435 - val_accuracy: 0.4719\n",
      "Epoch 4/25\n",
      "15625/15625 [==============================] - 23s 1ms/step - loss: 1.4208 - accuracy: 0.4809 - val_loss: 1.4400 - val_accuracy: 0.4722\n",
      "Epoch 5/25\n",
      "15625/15625 [==============================] - 18s 1ms/step - loss: 1.4150 - accuracy: 0.4829 - val_loss: 1.4391 - val_accuracy: 0.4734\n",
      "Epoch 6/25\n",
      "15625/15625 [==============================] - 23s 1ms/step - loss: 1.4103 - accuracy: 0.4851 - val_loss: 1.4383 - val_accuracy: 0.4746\n",
      "Epoch 7/25\n",
      "15625/15625 [==============================] - 22s 1ms/step - loss: 1.4070 - accuracy: 0.4864 - val_loss: 1.4384 - val_accuracy: 0.4737\n",
      "Epoch 8/25\n",
      "15625/15625 [==============================] - 23s 1ms/step - loss: 1.4041 - accuracy: 0.4872 - val_loss: 1.4407 - val_accuracy: 0.4734\n",
      "Epoch 9/25\n",
      "15625/15625 [==============================] - 22s 1ms/step - loss: 1.4017 - accuracy: 0.4884 - val_loss: 1.4419 - val_accuracy: 0.4731\n",
      "Epoch 10/25\n",
      "15625/15625 [==============================] - 22s 1ms/step - loss: 1.3995 - accuracy: 0.4886 - val_loss: 1.4405 - val_accuracy: 0.4738\n",
      "Epoch 11/25\n",
      "15625/15625 [==============================] - 23s 1ms/step - loss: 1.3974 - accuracy: 0.4897 - val_loss: 1.4462 - val_accuracy: 0.4697\n",
      "Epoch 12/25\n",
      "15625/15625 [==============================] - 20s 1ms/step - loss: 1.3960 - accuracy: 0.4902 - val_loss: 1.4426 - val_accuracy: 0.4748\n",
      "Epoch 13/25\n",
      "15625/15625 [==============================] - 24s 2ms/step - loss: 1.3944 - accuracy: 0.4907 - val_loss: 1.4411 - val_accuracy: 0.4733\n",
      "Epoch 14/25\n",
      "15625/15625 [==============================] - 26s 2ms/step - loss: 1.3930 - accuracy: 0.4914 - val_loss: 1.4438 - val_accuracy: 0.4735\n",
      "Epoch 15/25\n",
      "15625/15625 [==============================] - 23s 1ms/step - loss: 1.3918 - accuracy: 0.4920 - val_loss: 1.4433 - val_accuracy: 0.4750\n",
      "Epoch 16/25\n",
      "15625/15625 [==============================] - 22s 1ms/step - loss: 1.3904 - accuracy: 0.4922 - val_loss: 1.4457 - val_accuracy: 0.4731\n",
      "Epoch 17/25\n",
      "15625/15625 [==============================] - 24s 2ms/step - loss: 1.3896 - accuracy: 0.4931 - val_loss: 1.4462 - val_accuracy: 0.4729\n",
      "Epoch 18/25\n",
      "15625/15625 [==============================] - 20s 1ms/step - loss: 1.3885 - accuracy: 0.4931 - val_loss: 1.4466 - val_accuracy: 0.4726\n",
      "Epoch 19/25\n",
      "15625/15625 [==============================] - 20s 1ms/step - loss: 1.3877 - accuracy: 0.4935 - val_loss: 1.4484 - val_accuracy: 0.4721\n",
      "Epoch 20/25\n",
      "15625/15625 [==============================] - 20s 1ms/step - loss: 1.3869 - accuracy: 0.4937 - val_loss: 1.4459 - val_accuracy: 0.4729\n",
      "Epoch 21/25\n",
      "15625/15625 [==============================] - 21s 1ms/step - loss: 1.3860 - accuracy: 0.4940 - val_loss: 1.4477 - val_accuracy: 0.4745\n",
      "Epoch 22/25\n",
      "15625/15625 [==============================] - 22s 1ms/step - loss: 1.3852 - accuracy: 0.4944 - val_loss: 1.4484 - val_accuracy: 0.4744\n",
      "Epoch 23/25\n",
      "15625/15625 [==============================] - 22s 1ms/step - loss: 1.3846 - accuracy: 0.4946 - val_loss: 1.4558 - val_accuracy: 0.4697\n",
      "Epoch 24/25\n",
      "15625/15625 [==============================] - 22s 1ms/step - loss: 1.3838 - accuracy: 0.4951 - val_loss: 1.4491 - val_accuracy: 0.4734\n",
      "Epoch 25/25\n",
      "15625/15625 [==============================] - 22s 1ms/step - loss: 1.3836 - accuracy: 0.4952 - val_loss: 1.4519 - val_accuracy: 0.4734\n",
      "training finish\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger],\n",
    "                    validation_data = (X_test, y_test))\n",
    "print('training finish')\n",
    "model.save('BOW300_500k.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\grace\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "c:\\users\\grace\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test), label_decode(label_encoder,y_test_pred)), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4)  Predict and write submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_unknown = BOW_vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_unknown_pred = model.predict(X_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\grace\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_unknown_pred = label_decode(label_encoder, y_unknown_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test = {\n",
    "    \"id\":list(test_df['id']),\n",
    "    \"emotion\":list(y_unknown_pred)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test = pd.DataFrame(predict_test)\n",
    "predict_test.to_csv('BOW300_500k.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 500 features and more training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "BOW_vectorizer = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "# 1. Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "num_of_train = int(len(train_df)*3/4)\n",
    "BOW_vectorizer.fit(train_df['text'][:num_of_train])\n",
    "\n",
    "# 2. Transform documents to document-term matrix.\n",
    "X_train = BOW_vectorizer.transform(train_df['text'][:num_of_train])\n",
    "y_train = train_df['emotion'][:num_of_train]\n",
    "X_test = BOW_vectorizer.transform(train_df['text'][num_of_train:])\n",
    "y_test = train_df['emotion'][num_of_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1091672, 500)\n",
      "y_train.shape:  (1091672,)\n",
      "X_test.shape:  (363891, 500)\n",
      "y_test.shape:  (363891,)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "## check dimension is a good habbit \n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  500\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=64)(X)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=64)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "34115/34115 [==============================] - 47s 1ms/step - loss: 1.4191 - accuracy: 0.4825 - val_loss: 1.3924 - val_accuracy: 0.4931\n",
      "Epoch 2/9\n",
      "34115/34115 [==============================] - 54s 2ms/step - loss: 1.3777 - accuracy: 0.4970 - val_loss: 1.3808 - val_accuracy: 0.4969\n",
      "Epoch 3/9\n",
      "34115/34115 [==============================] - 56s 2ms/step - loss: 1.3662 - accuracy: 0.5016 - val_loss: 1.3789 - val_accuracy: 0.4974\n",
      "Epoch 4/9\n",
      "34115/34115 [==============================] - 56s 2ms/step - loss: 1.3598 - accuracy: 0.5039 - val_loss: 1.3730 - val_accuracy: 0.5000\n",
      "Epoch 5/9\n",
      "34115/34115 [==============================] - 56s 2ms/step - loss: 1.3556 - accuracy: 0.5056 - val_loss: 1.3720 - val_accuracy: 0.5007\n",
      "Epoch 6/9\n",
      "34115/34115 [==============================] - 56s 2ms/step - loss: 1.3524 - accuracy: 0.5065 - val_loss: 1.3715 - val_accuracy: 0.5007\n",
      "Epoch 7/9\n",
      "34115/34115 [==============================] - 55s 2ms/step - loss: 1.3499 - accuracy: 0.5072 - val_loss: 1.3779 - val_accuracy: 0.4993\n",
      "Epoch 8/9\n",
      "34115/34115 [==============================] - 59s 2ms/step - loss: 1.3479 - accuracy: 0.5084 - val_loss: 1.3740 - val_accuracy: 0.5011\n",
      "Epoch 9/9\n",
      "34115/34115 [==============================] - 59s 2ms/step - loss: 1.3464 - accuracy: 0.5092 - val_loss: 1.3754 - val_accuracy: 0.5007\n",
      "training finish\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 9\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger],\n",
    "                    validation_data = (X_test, y_test))\n",
    "print('training finish')\n",
    "model.save('BOW500_1350k_e9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test), label_decode(label_encoder,y_test_pred)), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is better. Upload this one to competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unknown = BOW_vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unknown_pred = model.predict(X_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unknown_pred = label_decode(label_encoder, y_unknown_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = {\n",
    "    \"id\":list(test_df['id']),\n",
    "    \"emotion\":list(y_unknown_pred)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = pd.DataFrame(predict_test)\n",
    "predict_test.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
